{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Script to transform Dental AI image segmentation dataset to YOLOv8 object detection dataset format\n",
    "\n",
    "# 1. Create a \"dataset\" folder in the same folder where this script\n",
    "# 2. Copy Dental AI dataset to the created \"dataset\" folder\n",
    "# 3. Run this code\n",
    "# 4. The transformed dataset will be created in the \"yolo_dataset\" folder\n",
    "\n",
    "# --------------- not in this script ------------------\n",
    "# 5. Use the transformed dataset in the \"yolo_dataset\" folder as a regular YOLOv8 dataset to train your model on it\n",
    "#    as described in the article (see train.ipynb as a sample)\n",
    "# 6. After train finished, the best trained model will be written to runs/detect/train/weights/best.pt file in the current folder\n",
    "# 7. Use the trained model file to make detections on your own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import shutil\n",
    "from os import path\n",
    "import os\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Define locations of source and destination datasets\n",
    "SRC_DIR = \"dataset\"\n",
    "DEST_DIR = \"yolo_dataset\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create folder structure of destination dataset\n",
    "os.makedirs(path.join(DEST_DIR, \"train\", \"images\"), exist_ok=True)\n",
    "os.makedirs(path.join(DEST_DIR, \"train\", \"labels\"), exist_ok=True)\n",
    "os.makedirs(path.join(DEST_DIR, \"val\", \"images\"), exist_ok=True)\n",
    "os.makedirs(path.join(DEST_DIR, \"val\", \"labels\"), exist_ok=True)\n",
    "os.makedirs(path.join(DEST_DIR, \"test\", \"images\"), exist_ok=True)\n",
    "os.makedirs(path.join(DEST_DIR, \"test\", \"labels\"), exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Caries': 0, 'Cavity': 1, 'Crack': 2, 'Tooth': 3}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From source model load classes that this dataset contains\n",
    "meta = json.load(open(path.join(SRC_DIR,\"meta.json\")))\n",
    "classes = {}\n",
    "for (index, entry) in enumerate(meta[\"classes\"]):\n",
    "    classes[entry[\"title\"]] = index\n",
    "classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Create the \"data.yaml\" file in destination dataset\n",
    "# with classes, that this dataset will contain\n",
    "with open(path.join(DEST_DIR,\"data.yaml\"),\"w\") as fp:\n",
    "    fp.write(\"train: ../train/images\\n\")\n",
    "    fp.write(\"val: ../val/images\\n\")\n",
    "    fp.write(\"test: ../test/images\\n\")\n",
    "    fp.write(\"\\n\")\n",
    "    fp.write(\"nc: {}\\n\".format(len(classes)))\n",
    "    fp.write(\"names: ['{}']\".format(\"','\".join(classes.keys())))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dirs_map = {\"train\": \"train\", \"valid\": \"val\", \"test\":\"test\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Copy images and transform annotations\n",
    "points = []\n",
    "for (src_dir, dest_dir) in dirs_map.items():\n",
    "    # Copy all images from source to destination dataset\n",
    "    shutil.copytree(path.join(SRC_DIR,src_dir,\"img\"),path.join(DEST_DIR,dest_dir,\"images\"),dirs_exist_ok=True)\n",
    "    # Go over each annotation file, transform annotations to YOLOv8 format\n",
    "    # and write to the destination dataset\n",
    "    for file in os.listdir(path.join(SRC_DIR,src_dir,\"ann\")):\n",
    "        ann = json.load(open(path.join(SRC_DIR,src_dir,\"ann\",file),\"r\"))\n",
    "        # get width and height of the image\n",
    "        img_width = ann[\"size\"][\"width\"]\n",
    "        img_height = ann[\"size\"][\"height\"]\n",
    "        # Create the annotation file in the destination dataset\n",
    "        file_name = file.replace(\".jpg.json\",\".txt\")\n",
    "        fp = open(path.join(DEST_DIR,dest_dir,\"labels\",file_name),\"w\")\n",
    "        # Calculate bounding boxes for each object, defined in this annotation file\n",
    "        for obj in ann[\"objects\"]:\n",
    "            # Get a class code for this bounding box\n",
    "            class_id = classes[obj[\"classTitle\"]]\n",
    "            top = 999999\n",
    "            left = 999999\n",
    "            bottom = 0\n",
    "            right = 0\n",
    "            for point in obj[\"points\"][\"exterior\"]:\n",
    "                # Determine the top left and right bottom corners of bounding box\n",
    "                if point[0]<left:\n",
    "                    left = point[0]\n",
    "                if point[0]>right:\n",
    "                    right = point[0]\n",
    "                if point[1]<top:\n",
    "                    top = point[1]\n",
    "                if point[1]>bottom:\n",
    "                    bottom = point[1]\n",
    "                # calculate bounding box in YOLOv8 format with normalization (x_center,y_center,width_height)\n",
    "                width = right - left\n",
    "                height = bottom - top\n",
    "                x_center = (left+width/2)/img_width\n",
    "                y_center =(top+height/2)/img_height\n",
    "                width /= img_width\n",
    "                height /= img_height\n",
    "            # Write bounding box to the annotation file to destination dataset\n",
    "            fp.write(\"{} {} {} {} {}\\n\".format(class_id,x_center,y_center,width,height))\n",
    "        fp.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
